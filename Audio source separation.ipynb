{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @misc{musdb18, #citation for the MUSB18 dataset\n",
    "#   author       = {Rafii, Zafar and\n",
    "#                   Liutkus, Antoine and\n",
    "#                   Fabian-Robert St{\\\"o}ter and\n",
    "#                   Mimilakis, Stylianos Ioannis and\n",
    "#                   Bittner, Rachel},\n",
    "#   title        = {The {MUSDB18} corpus for music separation},\n",
    "#   month        = dec,\n",
    "#   year         = 2017,\n",
    "#   doi          = {10.5281/zenodo.1117372},\n",
    "#   url          = {https://doi.org/10.5281/zenodo.1117372}\n",
    "# }\n",
    "\n",
    "# @inproceedings{Salamon:Scaper:WASPAA:17, #citation for the Scaper library\n",
    "#   author       = {Salamon, J. and MacConnell, D. and Cartwright, M. and Li, P. and Bello, J.~P.},\n",
    "#   title        = {Scaper: A Library for Soundscape Synthesis and Augmentation},\n",
    "#   booktitle.   = {IEEE Workshop on Applications of Signal Processing to Audio and Acoustics (WASPAA)},\n",
    "#   month        = {Oct.},\n",
    "#   year         = {2017},\n",
    "#   pages        = {344--348}\n",
    "# }\n",
    "\n",
    "# %matplotlib notebook\n",
    "# %matplotlib widget\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import librosa\n",
    "import librosa.display\n",
    "import musdb\n",
    "import museval\n",
    "import ffmpeg\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from IPython.display import Audio, display\n",
    "from numpy import load\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nussl\n",
    "import IPython\n",
    "# To keep things clean we'll hide all warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this command to download X 7-second clips from MUSDB18\n",
    "musdb = nussl.datasets.MUSDB18(download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93]\n"
     ]
    }
   ],
   "source": [
    "musdb_train = nussl.datasets.MUSDB18(subsets=['train'])\n",
    "print(musdb_train.items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['mix', 'sources', 'metadata'])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = 0\n",
    "item = musdb_train[idx]\n",
    "item.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for stem_label in item['sources'].keys():\n",
    "#     print(stem_label)\n",
    "#     audio_player = Audio(data=item['sources'][stem_label].audio_data, rate=item['sources'][stem_label].sample_rate)\n",
    "#     IPython.display.display(audio_player)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "# matplotlib.use('Agg')  # or another backend, like 'TkAgg'\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# create foreground folder\n",
    "fg_folder = Path('~/.nussl/ismir2020-tutorial/foreground').expanduser()  \n",
    "fg_folder.mkdir(parents=True, exist_ok=True)                             \n",
    "\n",
    "# create background folder - we need to provide one even if we don't use it\n",
    "bg_folder = Path('~/.nussl/ismir2020-tutorial/background').expanduser()\n",
    "bg_folder.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each item (track) in the train set, iterate over its sources (stems),\n",
    "# create a folder for the stem if it doesn't exist already (drums, bass, vocals, other) \n",
    "# and place the stem audio file in this folder, using the song name as the filename\n",
    "for item in musdb_train:\n",
    "    song_name = item['mix'].file_name\n",
    "    for key, val in item['sources'].items():\n",
    "        src_path = fg_folder / key \n",
    "        src_path.mkdir(exist_ok=True)\n",
    "        src_path = str(src_path / song_name) + '.wav'\n",
    "        val.write_audio_to_file(src_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "bass\tfolder contains 94 audio files:\n",
      "\n",
      "\t\tA Classic Education - NightOwl.wav\n",
      "\t\tANiMAL - Clinic A.wav\n",
      "\t\tANiMAL - Easy Tiger.wav\n",
      "\t\tANiMAL - Rockshow.wav\n",
      "\t\tActions - Devil's Words.wav\n",
      "\t\t...\n",
      "\n",
      "drums\tfolder contains 94 audio files:\n",
      "\n",
      "\t\tA Classic Education - NightOwl.wav\n",
      "\t\tANiMAL - Clinic A.wav\n",
      "\t\tANiMAL - Easy Tiger.wav\n",
      "\t\tANiMAL - Rockshow.wav\n",
      "\t\tActions - Devil's Words.wav\n",
      "\t\t...\n",
      "\n",
      "other\tfolder contains 94 audio files:\n",
      "\n",
      "\t\tA Classic Education - NightOwl.wav\n",
      "\t\tANiMAL - Clinic A.wav\n",
      "\t\tANiMAL - Easy Tiger.wav\n",
      "\t\tANiMAL - Rockshow.wav\n",
      "\t\tActions - Devil's Words.wav\n",
      "\t\t...\n",
      "\n",
      "vocals\tfolder contains 94 audio files:\n",
      "\n",
      "\t\tA Classic Education - NightOwl.wav\n",
      "\t\tANiMAL - Clinic A.wav\n",
      "\t\tANiMAL - Easy Tiger.wav\n",
      "\t\tANiMAL - Rockshow.wav\n",
      "\t\tActions - Devil's Words.wav\n",
      "\t\t...\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "\n",
    "for folder in os.listdir(fg_folder):\n",
    "    if folder[0] != '.':  # ignore system folders\n",
    "        stem_files = os.listdir(os.path.join(fg_folder, folder))\n",
    "        print(f\"\\n{folder}\\tfolder contains {len(stem_files)} audio files:\\n\")\n",
    "        for sf in sorted(stem_files)[:5]:\n",
    "            print(f\"\\t\\t{sf}\")\n",
    "        print(\"\\t\\t...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scaper\n",
    "\n",
    "seed = 123 # integer or np.random.RandomState(<integer>)\n",
    "\n",
    "sc = scaper.Scaper(\n",
    "    duration=6.0,\n",
    "    fg_path=str(fg_folder),\n",
    "    bg_path=str(bg_folder),\n",
    "    random_state=seed\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.sr = 44100\n",
    "sc.n_channels = 1\n",
    "sc.ref_db = -20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jams\n",
    "import soundfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['vocals', 'drums', 'bass', 'other']\n",
    "\n",
    "for label in labels:\n",
    "    sc.add_event(label=('const', label),                # set the label value explicitly using a constant\n",
    "                 source_file=('choose', []),            # choose the source file randomly from all files in the folder\n",
    "                 source_time=('uniform', 0, 7),         # sample the source (stem) audio starting at a time between 0-7\n",
    "                 event_time=('const', 0),               # always add the stem at time 0 in the mixture\n",
    "                 event_duration=('const', sc.duration), # set the stem duration to match the mixture duration\n",
    "                 snr=('uniform', -5, 5),                # choose an SNR for the stem uniformly between -5 and 5 dB\n",
    "                 pitch_shift=('uniform', -2, 2),        # apply a random pitch shift between -2 and 2 semitones\n",
    "                 time_stretch=('uniform', 0.8, 1.2))    # apply a random time stretch between 0.8 (faster) and 1.2 (slower)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_and_play(sc):\n",
    "\n",
    "    mixture_audio, mixture_jam, annotation_list, stem_audio_list = sc.generate(fix_clipping=True)\n",
    "\n",
    "    print(\"Mixture:\")\n",
    "    display(Audio(data=mixture_audio.T, rate=sc.sr))\n",
    "\n",
    "    # extract the annotation data from the JAMS object\n",
    "    ann = mixture_jam.annotations.search(namespace='scaper')[0]\n",
    "    \n",
    "    # iterate over the annotation and corresponding stem audio data\n",
    "    for obs, stem_audio in zip(ann.data, stem_audio_list):\n",
    "        print(f\"Instrument: {obs.value['label']} at SNR: {obs.value['snr']:.2f}\")\n",
    "        display(Audio(data=stem_audio.T, rate=sc.sr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a template of probabilistic event parameters\n",
    "template_event_parameters = {\n",
    "    'label': ('const', 'vocals'),\n",
    "    'source_file': ('choose', []),\n",
    "    'source_time': ('uniform', 0, 7),\n",
    "    'event_time': ('const', 0),\n",
    "    'event_duration': ('const', 6.0),\n",
    "    'snr': ('uniform', -5, 5),\n",
    "    'pitch_shift': ('uniform', -2, 2),\n",
    "    'time_stretch': ('uniform', 0.8, 1.2)\n",
    "}\n",
    "\n",
    "\n",
    "def incoherent(fg_folder, bg_folder, event_template, seed):\n",
    "    \"\"\"\n",
    "    This function takes the paths to the MUSDB18 source materials, an event template, \n",
    "    and a random seed, and returns an INCOHERENT mixture (audio + annotations). \n",
    "    \n",
    "    Stems in INCOHERENT mixtures may come from different songs and are not temporally\n",
    "    aligned.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    fg_folder : str\n",
    "        Path to the foreground source material for MUSDB18\n",
    "    bg_folder : str\n",
    "        Path to the background material for MUSDB18 (empty folder)\n",
    "    event_template: dict\n",
    "        Dictionary containing a template of probabilistic event parameters\n",
    "    seed : int or np.random.RandomState()\n",
    "        Seed for setting the Scaper object's random state. Different seeds will \n",
    "        generate different mixtures for the same source material and event template.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    mixture_audio : np.ndarray\n",
    "        Audio signal for the mixture\n",
    "    mixture_jams : np.ndarray\n",
    "        JAMS annotation for the mixture\n",
    "    annotation_list : list\n",
    "        Simple annotation in list format\n",
    "    stem_audio_list : list\n",
    "        List containing the audio signals of the stems that comprise the mixture\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create scaper object and seed random state\n",
    "    sc = scaper.Scaper(\n",
    "        duration=6.0,\n",
    "        fg_path=str(fg_folder),\n",
    "        bg_path=str(bg_folder),\n",
    "        random_state=seed\n",
    "    )\n",
    "    \n",
    "    # Set sample rate, reference dB, and channels (mono)\n",
    "    sc.sr = 44100\n",
    "    sc.ref_db = -20\n",
    "    sc.n_channels = 1\n",
    "    \n",
    "    # Copy the template so we can change it\n",
    "    event_parameters = event_template.copy()\n",
    "    \n",
    "    # Iterate over stem types and add INCOHERENT events\n",
    "    labels = ['vocals', 'drums', 'bass', 'other']\n",
    "    for label in labels:\n",
    "        event_parameters['label'] = ('const', label)\n",
    "        sc.add_event(**event_parameters)\n",
    "    \n",
    "    # Return the generated mixture audio + annotations \n",
    "    # while ensuring we prevent audio clipping\n",
    "    return sc.generate(fix_clipping=True)\n",
    "\n",
    "\n",
    "def coherent(fg_folder, bg_folder, event_template, seed):\n",
    "    \"\"\"\n",
    "    This function takes the paths to the MUSDB18 source materials and a random seed,\n",
    "    and returns an COHERENT mixture (audio + annotations).\n",
    "    \n",
    "    Stems in COHERENT mixtures come from the same song and are temporally aligned.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    fg_folder : str\n",
    "        Path to the foreground source material for MUSDB18\n",
    "    bg_folder : str\n",
    "        Path to the background material for MUSDB18 (empty folder)\n",
    "    event_template: dict\n",
    "        Dictionary containing a template of probabilistic event parameters\n",
    "    seed : int or np.random.RandomState()\n",
    "        Seed for setting the Scaper object's random state. Different seeds will \n",
    "        generate different mixtures for the same source material and event template.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    mixture_audio : np.ndarray\n",
    "        Audio signal for the mixture\n",
    "    mixture_jams : np.ndarray\n",
    "        JAMS annotation for the mixture\n",
    "    annotation_list : list\n",
    "        Simple annotation in list format\n",
    "    stem_audio_list : list\n",
    "        List containing the audio signals of the stems that comprise the mixture\n",
    "    \"\"\"\n",
    "        \n",
    "    # Create scaper object and seed random state\n",
    "    sc = scaper.Scaper(\n",
    "        duration=6.0,\n",
    "        fg_path=str(fg_folder),\n",
    "        bg_path=str(bg_folder),\n",
    "        random_state=seed\n",
    "    )\n",
    "    \n",
    "    # Set sample rate, reference dB, and channels (mono)\n",
    "    sc.sr = 44100\n",
    "    sc.ref_db = -20\n",
    "    sc.n_channels = 1\n",
    "    \n",
    "    # Copy the template so we can change it\n",
    "    event_parameters = event_template.copy()    \n",
    "    \n",
    "    # Instatiate the template once to randomly choose a song,   \n",
    "    # a start time for the sources, a pitch shift and a time    \n",
    "    # stretch. These values must remain COHERENT across all stems\n",
    "    sc.add_event(**event_parameters)\n",
    "    event = sc._instantiate_event(sc.fg_spec[0])\n",
    "    \n",
    "    # Reset the Scaper object's the event specification\n",
    "    sc.reset_fg_event_spec()\n",
    "    \n",
    "    # Replace the distributions for source time, pitch shift and \n",
    "    # time stretch with the constant values we just sampled, to  \n",
    "    # ensure our added events (stems) are coherent.              \n",
    "    event_parameters['source_time'] = ('const', event.source_time)\n",
    "    event_parameters['pitch_shift'] = ('const', event.pitch_shift)\n",
    "    event_parameters['time_stretch'] = ('const', event.time_stretch)\n",
    "\n",
    "    # Iterate over the four stems (vocals, drums, bass, other) and \n",
    "    # add COHERENT events.                                         \n",
    "    labels = ['vocals', 'drums', 'bass', 'other']\n",
    "    for label in labels:\n",
    "        \n",
    "        # Set the label to the stem we are adding\n",
    "        event_parameters['label'] = ('const', label)\n",
    "        \n",
    "        # To ensure coherent source files (all from the same song), we leverage\n",
    "        # the fact that all the stems from the same song have the same filename.\n",
    "        # All we have to do is replace the stem file's parent folder name from \"vocals\" \n",
    "        # to the label we are adding in this iteration of the loop, which will give the \n",
    "        # correct path to the stem source file for this current label.\n",
    "        coherent_source_file = event.source_file.replace('vocals', label)\n",
    "        event_parameters['source_file'] = ('const', coherent_source_file)\n",
    "        # Add the event using the modified, COHERENT, event parameters\n",
    "        sc.add_event(**event_parameters)\n",
    "    \n",
    "    # Generate and return the mixture audio, stem audio, and annotations\n",
    "    return sc.generate(fix_clipping=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # First double check our paths and template are correct:\n",
    "# print(fg_folder)\n",
    "# print(bg_folder)\n",
    "# print(\"\")\n",
    "# print(template_event_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def generate_mixture(dataset, fg_folder, bg_folder, event_template, seed):\n",
    "    \n",
    "    # hide warnings\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.filterwarnings('ignore')\n",
    "        \n",
    "        # flip a coint to choose coherent or incoherent mixing\n",
    "        random_state = np.random.RandomState(seed)\n",
    "        \n",
    "        # generate mixture\n",
    "        if random_state.rand() > .5:\n",
    "            data = coherent(fg_folder, bg_folder, event_template, seed)\n",
    "        else:\n",
    "            data = incoherent(fg_folder, bg_folder, event_template, seed)\n",
    "            \n",
    "    # unpack the data\n",
    "    mixture_audio, mixture_jam, annotation_list, stem_audio_list = data\n",
    "    \n",
    "    # convert mixture to nussl format\n",
    "    mix = dataset._load_audio_from_array(\n",
    "        audio_data=mixture_audio, sample_rate=dataset.sample_rate\n",
    "    )\n",
    "    \n",
    "    # convert stems to nussl format\n",
    "    sources = {}\n",
    "    ann = mixture_jam.annotations.search(namespace='scaper')[0]\n",
    "    for obs, stem_audio in zip(ann.data, stem_audio_list):\n",
    "        key = obs.value['label']\n",
    "        sources[key] = dataset._load_audio_from_array(\n",
    "            audio_data=stem_audio, sample_rate=dataset.sample_rate\n",
    "        )\n",
    "    \n",
    "    # store the mixture, stems and JAMS annotation in the format expected by nussl\n",
    "    output = {\n",
    "        'mix': mix,\n",
    "        'sources': sources,\n",
    "        'metadata': mixture_jam\n",
    "    }\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convenience class so we don't need to enter the fg_folder, bg_folder, and template each time\n",
    "class MixClosure:\n",
    "    \n",
    "    def __init__(self, fg_folder, bg_folder, event_template):\n",
    "        self.fg_folder = fg_folder\n",
    "        self.bg_folder = bg_folder\n",
    "        self.event_template = event_template\n",
    "        \n",
    "    def __call__(self, dataset, seed):\n",
    "        return generate_mixture(dataset, self.fg_folder, self.bg_folder, self.event_template, seed)\n",
    "    \n",
    "# Initialize our mixing function with our specific source material and event template\n",
    "mix_func = MixClosure(fg_folder, bg_folder, template_event_parameters)\n",
    "\n",
    "# Create a nussle OnTheFly data generator\n",
    "on_the_fly = nussl.datasets.OnTheFly(\n",
    "    num_mixtures=1000,\n",
    "    mix_closure=mix_func\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "stft_params = nussl.STFTParams(window_length=512, hop_length=128, window_type='sqrt_hann')\n",
    "fg_path = \"~/.nussl/tutorial/train\"\n",
    "# train_data = musdb_train.on_the_fly(stft_params, transform=None, fg_path=fg_path, num_mixtures=1000, coherent_prob=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "musdb_test = nussl.datasets.MUSDB18(subsets=['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "fg_path = \"~/.nussl/tutorial/test\"\n",
    "# test_data = musdb_test.on_the_fly(stft_params, transform=None, fg_path=fg_path, num_mixtures=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mix': <nussl.core.audio_signal.AudioSignal object at 0x0000023277A384C0>, 'sources': {'vocals': <nussl.core.audio_signal.AudioSignal object at 0x0000023277A905E0>, 'bass+drums+other': <nussl.core.audio_signal.AudioSignal object at 0x0000023277A90BB0>}, 'metadata': {'labels': ['bass', 'drums', 'other', 'vocals', 'bass+drums+other']}}\n"
     ]
    }
   ],
   "source": [
    "from nussl.datasets import transforms as nussl_tfm\n",
    "\n",
    "item = musdb_train[0]\n",
    "sum_sources = nussl_tfm.SumSources([['bass', 'drums', 'other']])\n",
    "item = sum_sources(item)\n",
    "print(item)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['mix', 'sources', 'metadata', 'mix_magnitude', 'ideal_binary_mask', 'source_magnitudes'])\n"
     ]
    }
   ],
   "source": [
    "msa = nussl_tfm.MagnitudeSpectrumApproximation()\n",
    "item = msa(item)\n",
    "\n",
    "print(item.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1025, 587, 2, 2) (1025, 587, 2) (1025, 587, 2, 2)\n"
     ]
    }
   ],
   "source": [
    "print(item['source_magnitudes'].shape, item['mix_magnitude'].shape, item['ideal_binary_mask'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# plt.imshow(item['source_magnitudes'][..., 1][..., 0], aspect='auto', origin='lower')\n",
    "# plt.title('Magnitude spectrogram of vocals source')\n",
    "# plt.xlabel('Time frame')\n",
    "# plt.ylabel('Frequency bin')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_sources = nussl_tfm.IndexSources('source_magnitudes', 1)\n",
    "item = index_sources(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# plt.imshow(item['source_magnitudes'][..., 0, 0], aspect='auto', origin='lower')\n",
    "# plt.title('Magnitude spectrogram of vocals source')\n",
    "# plt.xlabel('Time frame')\n",
    "# plt.ylabel('Frequency bin')\n",
    "# plt.show()\n",
    "\n",
    "# print(item['source_magnitudes'].shape, item['mix_magnitude'].shape, item['ideal_binary_mask'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_separation_model = nussl_tfm.ToSeparationModel()\n",
    "item = to_separation_model(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['mix_magnitude', 'ideal_binary_mask', 'source_magnitudes'])\n",
      "mix_magnitude <class 'torch.Tensor'> torch.Size([587, 1025, 2])\n",
      "ideal_binary_mask <class 'torch.Tensor'> torch.Size([587, 1025, 2, 2])\n",
      "source_magnitudes <class 'torch.Tensor'> torch.Size([587, 1025, 2, 1])\n"
     ]
    }
   ],
   "source": [
    "print(item.keys())\n",
    "for key in item:\n",
    "    print(key, type(item[key]), item[key].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before transforms\n",
      "mix <class 'nussl.core.audio_signal.AudioSignal'>\n",
      "sources <class 'dict'>\n",
      "metadata <class 'dict'>\n",
      "\n",
      "After transforms\n",
      "mix_magnitude <class 'torch.Tensor'>\n",
      "ideal_binary_mask <class 'torch.Tensor'>\n",
      "source_magnitudes <class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "tfm = nussl_tfm.Compose([\n",
    "    nussl_tfm.SumSources([['bass', 'drums', 'other']]),\n",
    "    nussl_tfm.MagnitudeSpectrumApproximation(),\n",
    "    nussl_tfm.IndexSources('source_magnitudes', 1),\n",
    "    nussl_tfm.ToSeparationModel(),\n",
    "])\n",
    "\n",
    "item = musdb_train[0]\n",
    "print(\"Before transforms\")\n",
    "for key in item:\n",
    "    print(key, type(item[key]))\n",
    "print(\"\\nAfter transforms\")\n",
    "item = tfm(item)\n",
    "for key in item:\n",
    "    print(key, type(item[key]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def audio_to_spectrogram(audio, sr=44100, n_fft=2048, hop_length=1024, window='hann', center=True):\n",
    "    spectrogram = librosa.stft(y=audio[:, 0], n_fft=n_fft, hop_length=hop_length, window=window, center=center)\n",
    "    return librosa.amplitude_to_db(np.abs(spectrogram), ref=np.max)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def generate_mixture(dataset, fg_folder, bg_folder, event_template, seed):\n",
    "    \n",
    "    # hide warnings\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.filterwarnings('ignore')\n",
    "        \n",
    "        # flip a coint to choose coherent or incoherent mixing\n",
    "        random_state = np.random.RandomState(seed)\n",
    "        \n",
    "        # generate mixture\n",
    "        if random_state.rand() > .5:\n",
    "            data = coherent(fg_folder, bg_folder, event_template, seed)\n",
    "        else:\n",
    "            data = incoherent(fg_folder, bg_folder, event_template, seed)\n",
    "            \n",
    "    # unpack the data\n",
    "    mixture_audio, mixture_jam, annotation_list, stem_audio_list = data\n",
    "    \n",
    "    # convert mixture to nussl format\n",
    "    mix = dataset._load_audio_from_array(\n",
    "        audio_data=mixture_audio, sample_rate=dataset.sample_rate\n",
    "    )\n",
    "    \n",
    "    # convert stems to nussl format\n",
    "    sources = {}\n",
    "    ann = mixture_jam.annotations.search(namespace='scaper')[0]\n",
    "    for obs, stem_audio in zip(ann.data, stem_audio_list):\n",
    "        key = obs.value['label']\n",
    "        sources[key] = dataset._load_audio_from_array(\n",
    "            audio_data=stem_audio, sample_rate=dataset.sample_rate\n",
    "        )\n",
    "    \n",
    "    # store the mixture, stems and JAMS annotation in the format expected by nussl\n",
    "    output = {\n",
    "        'mix': mix,\n",
    "        'sources': sources,\n",
    "        'metadata': mixture_jam\n",
    "    }\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# create foreground folder\n",
    "fg_folder = Path('~/.nussl/ismir2020-tutorial/foreground').expanduser()  \n",
    "fg_folder.mkdir(parents=True, exist_ok=True)                             \n",
    "\n",
    "# create background folder - we need to provide one even if we don't use it\n",
    "bg_folder = Path('~/.nussl/ismir2020-tutorial/background').expanduser()\n",
    "bg_folder.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Convenience class so we don't need to enter the fg_folder, bg_folder, and template each time\n",
    "class MixClosure:\n",
    "    \n",
    "    def __init__(self, fg_folder, bg_folder, event_template):\n",
    "        self.fg_folder = fg_folder\n",
    "        self.bg_folder = bg_folder\n",
    "        self.event_template = event_template\n",
    "        \n",
    "    def __call__(self, dataset, seed):\n",
    "        return generate_mixture(dataset, self.fg_folder, self.bg_folder, self.event_template, seed)\n",
    "    \n",
    "# Initialize our mixing function with our specific source material and event template\n",
    "mix_func = MixClosure(fg_folder, bg_folder, template_event_parameters)\n",
    "\n",
    "# Create a nussle OnTheFly data generator\n",
    "on_the_fly = nussl.datasets.OnTheFly(\n",
    "    num_mixtures=1000,\n",
    "    mix_closure=mix_func\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import librosa\n",
    "\n",
    "def generate_spectrograms(mixture_audio, stem_audio_list):\n",
    "    mixture_spectrogram = np.abs(librosa.stft(mixture_audio.squeeze())).astype(np.float32)\n",
    "    stem_spectrograms = [np.abs(librosa.stft(stem_audio.squeeze())).astype(np.float32) for stem_audio in stem_audio_list]\n",
    "    return mixture_spectrogram, stem_spectrograms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.utils import Sequence\n",
    "\n",
    "class CustomDataGenerator(Sequence):\n",
    "    def __init__(self, fg_folder, bg_folder, event_template, batch_size=1, num_batches=100, shuffle=True, seed=None):\n",
    "        self.fg_folder = fg_folder\n",
    "        self.bg_folder = bg_folder\n",
    "        self.event_template = event_template\n",
    "        self.batch_size = batch_size\n",
    "        self.num_batches = num_batches\n",
    "        self.shuffle = shuffle\n",
    "        self.seed = seed if seed is not None else np.random.randint(1000000)\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_batches\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        if self.shuffle:\n",
    "            self.seed = np.random.randint(1000000)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        np.random.seed(self.seed + idx)\n",
    "        batch_mixtures = []\n",
    "        batch_stems = []\n",
    "\n",
    "        for _ in range(self.batch_size):\n",
    "            mixture_audio, _, _, stem_audio_list = incoherent(\n",
    "                self.fg_folder,\n",
    "                self.bg_folder,\n",
    "                self.event_template,\n",
    "                self.seed)\n",
    "            \n",
    "            mixture_spectrogram, stem_spectrograms = generate_spectrograms(mixture_audio, stem_audio_list)\n",
    "\n",
    "            batch_mixtures.append(mixture_spectrogram)\n",
    "            batch_stems.append(np.stack(stem_spectrograms))\n",
    "\n",
    "        batch_mixtures = np.array(batch_mixtures)\n",
    "        batch_stems = np.array(batch_stems)\n",
    "\n",
    "        return batch_mixtures, batch_stems\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# create foreground folder\n",
    "fg_folder = Path('~/.nussl/ismir2020-tutorial/foreground').expanduser()  \n",
    "fg_folder.mkdir(parents=True, exist_ok=True)                             \n",
    "\n",
    "# create background folder - we need to provide one even if we don't use it\n",
    "bg_folder = Path('~/.nussl/ismir2020-tutorial/background').expanduser()\n",
    "bg_folder.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "event_template = {\n",
    "    'label': ('const', 'vocals'),\n",
    "    'source_file': ('choose', []),\n",
    "    'source_time': ('uniform', 0, 7),\n",
    "    'event_time': ('const', 0),\n",
    "    'event_duration': ('const', 6.0),\n",
    "    'snr': ('uniform', -5, 5),\n",
    "    'pitch_shift': ('uniform', -2, 2),\n",
    "    'time_stretch': ('uniform', 0.8, 1.2)\n",
    "}\n",
    "\n",
    "train_generator = CustomDataGenerator(fg_folder, bg_folder, event_template, batch_size=1, num_batches=100, shuffle=True, seed=42)\n",
    "val_generator = CustomDataGenerator(fg_folder, bg_folder, event_template, batch_size=1, num_batches=20, shuffle=True, seed=84)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import librosa\n",
    "# import tensorflow as tf\n",
    "# from tensorflow.keras.optimizers import Adam\n",
    "# from tensorflow.keras.layers import Input, Conv1D, MaxPooling1D, UpSampling1D, concatenate, ZeroPadding1D, Reshape\n",
    "# from tensorflow.keras.models import Model\n",
    "\n",
    "# def unet_model(input_shape, num_sources):\n",
    "#     inputs = Input(input_shape)\n",
    "    \n",
    "#     # New Conv1D layer to adapt input shape\n",
    "#     adapt = Conv1D(16, 3, activation='relu', padding='same')(inputs)\n",
    "#     adapt = Reshape((-1, 16))(adapt)\n",
    "\n",
    "#     # Encoder\n",
    "#     conv1 = Conv1D(16, 3, activation='relu', padding='same')(adapt)\n",
    "#     pool1 = MaxPooling1D(pool_size=2)(conv1)\n",
    "\n",
    "#     conv2 = Conv1D(32, 3, activation='relu', padding='same')(pool1)\n",
    "#     pool2 = MaxPooling1D(pool_size=2)(conv2)\n",
    "\n",
    "#     # Bottleneck\n",
    "#     conv3 = Conv1D(64, 3, activation='relu', padding='same')(pool2)\n",
    "\n",
    "#     # Decoder\n",
    "#     up4 = concatenate([UpSampling1D(size=2)(conv3), conv2], axis=-1)\n",
    "#     conv4 = Conv1D(32, 3, activation='relu', padding='same')(up4)\n",
    "\n",
    "#     up5 = UpSampling1D(size=2)(conv4)\n",
    "#     up5 = ZeroPadding1D((1, 0))(up5)  # Add padding to match the dimensions\n",
    "#     up5 = concatenate([up5, conv1], axis=-1)\n",
    "    \n",
    "#     conv5 = Conv1D(16, 3, activation='relu', padding='same')(up5)\n",
    "\n",
    "#     # Output layer\n",
    "#     outputs = Conv1D(num_sources, 1, activation='linear')(conv5)\n",
    "#     outputs = Reshape((-1, num_sources))(outputs)\n",
    "\n",
    "#     return Model(inputs=[inputs], outputs=[outputs])\n",
    "\n",
    "\n",
    "# # Get a sample from the train_generator\n",
    "# train_iterator = iter(train_generator)\n",
    "# sample_input, sample_output = next(train_iterator)\n",
    "\n",
    "# # Get the input shape and number of sources\n",
    "# input_shape = sample_input.shape[1:3]\n",
    "# num_sources = sample_output.shape[-1]\n",
    "\n",
    "# # Create the U-Net model\n",
    "# model = unet_model(input_shape, num_sources)\n",
    "# model.summary()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import librosa\n",
    "# import tensorflow as tf\n",
    "# from tensorflow.keras.optimizers import Adam\n",
    "# from tensorflow.keras.layers import Input, Conv1D, MaxPooling1D, UpSampling1D, concatenate, ZeroPadding1D, Reshape\n",
    "# from tensorflow.keras.models import Model\n",
    "\n",
    "\n",
    "# def unet_model(input_shape, num_sources):\n",
    "#     inputs = Input(input_shape)\n",
    "\n",
    "#     # Encoder\n",
    "#     conv1 = Conv1D(16, 3, activation='relu', padding='same')(inputs)\n",
    "#     pool1 = MaxPooling1D(pool_size=2)(conv1)\n",
    "\n",
    "#     conv2 = Conv1D(32, 3, activation='relu', padding='same')(pool1)\n",
    "#     pool2 = MaxPooling1D(pool_size=2)(conv2)\n",
    "\n",
    "#     # Bottleneck\n",
    "#     conv3 = Conv1D(64, 3, activation='relu', padding='same')(pool2)\n",
    "\n",
    "#     # Decoder\n",
    "#     up4 = concatenate([UpSampling1D(size=2)(conv3), conv2], axis=-1)\n",
    "#     conv4 = Conv1D(32, 3, activation='relu', padding='same')(up4)\n",
    "\n",
    "#     up5 = UpSampling1D(size=2)(conv4)\n",
    "#     up5 = concatenate([up5, conv1], axis=-1)\n",
    "    \n",
    "#     conv5 = Conv1D(16, 3, activation='relu', padding='same')(up5)\n",
    "\n",
    "#     # Output layer\n",
    "#     outputs = Conv1D(4, 1, activation='linear', padding='same')(conv5)\n",
    "#     outputs = Reshape((4, -1, 1))(outputs)\n",
    "\n",
    "#     return Model(inputs=[inputs], outputs=[outputs])\n",
    "\n",
    "\n",
    "# input_shape = (264600, 1)\n",
    "# # Output layer\n",
    "\n",
    "# # Create the U-Net model\n",
    "# model = unet_model(input_shape, num_sources)\n",
    "# model.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# def preprocess_audio(audio):\n",
    "\n",
    "#     scaler = MinMaxScaler()\n",
    "#     audio = audio.reshape(audio.shape[0], -1)\n",
    "#     preprocessed_audio = scaler.fit_transform(audio).reshape(audio.shape)\n",
    "\n",
    "#     return preprocessed_audio\n",
    "\n",
    "# def dataset_generator_test(fg_folder, bg_folder, template_event_parameters, seed, batch_size=1):\n",
    "#     while True:\n",
    "#         X_batch = []\n",
    "#         y_batch = []\n",
    "        \n",
    "#         for _ in range(batch_size):\n",
    "#             mixture_audio, mixture_jam, annotation_list, stem_audio_list = incoherent(fg_folder, bg_folder, template_event_parameters, seed)\n",
    "#             x = mixture_audio[:, np.newaxis]\n",
    "#             y = np.stack([stem_audio[:, np.newaxis] for stem_audio in stem_audio_list], axis=0)\n",
    "\n",
    "#             X = preprocess_audio(mixture_audio)\n",
    "#             y = np.array([preprocess_audio(stem_audio) for stem_audio in stem_audio_list])\n",
    "            \n",
    "#             X_batch.append(X)\n",
    "#             y_batch.append(y)\n",
    "        \n",
    "#         X_batch = np.stack(X_batch, axis=0)\n",
    "#         y_batch = np.stack(y_batch, axis=0)\n",
    "        \n",
    "#         yield X_batch, y_batch\n",
    "\n",
    "# num_mixtures = np.random.randint(1, 2)\n",
    "\n",
    "# # Loop through the generator to retrieve X and y values\n",
    "# for i in range(num_mixtures):\n",
    "#     generator = dataset_generator_test(fg_folder, bg_folder, template_event_parameters, seed + i)\n",
    "#     for data in generator:\n",
    "#         X, y = data[:2]\n",
    "#         # print(f\"Mixture {i + 1}:\")\n",
    "#         print(\"X =\", X.shape)\n",
    "#         print(\"y =\", y.shape)\n",
    "#         break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# def preprocess_audio(audio):\n",
    "#     scaler = MinMaxScaler()\n",
    "#     audio = audio.reshape(audio.shape[0], -1)\n",
    "#     preprocessed_audio = scaler.fit_transform(audio).reshape(audio.shape)\n",
    "\n",
    "#     return preprocessed_audio\n",
    "\n",
    "# def dataset_generator(fg_folder, bg_folder, template_event_parameters, seed, batch_size=1):\n",
    "#     while True:\n",
    "#         X_batch = []\n",
    "#         y_batch_fg = []\n",
    "#         y_batch_bg = []\n",
    "        \n",
    "#         for _ in range(batch_size):\n",
    "#             mixture_audio, mixture_jam, annotation_list, stem_audio_list = incoherent(fg_folder, bg_folder, template_event_parameters, seed)\n",
    "#             x = mixture_audio[:, np.newaxis]\n",
    "#             y = np.stack([stem_audio[:, np.newaxis] for stem_audio in stem_audio_list], axis=0)\n",
    "\n",
    "#             X = preprocess_audio(mixture_audio)\n",
    "#             y = np.array([preprocess_audio(stem_audio) for stem_audio in stem_audio_list])\n",
    "            \n",
    "#             X_batch.append(X)\n",
    "#             y_batch_fg.append(y[0])  # Assuming foreground is the first stem\n",
    "#             y_batch_bg.append(y[1])  # Assuming background is the second stem\n",
    "        \n",
    "#         X_batch = np.stack(X_batch, axis=0)\n",
    "#         y_batch_fg = np.stack(y_batch_fg, axis=0)\n",
    "#         y_batch_bg = np.stack(y_batch_bg, axis=0)\n",
    "        \n",
    "#         yield X_batch, [y_batch_fg, y_batch_bg]\n",
    "\n",
    "# num_mixtures = np.random.randint(1, 2)\n",
    "\n",
    "# # Loop through the generator to retrieve X and y values\n",
    "# for i in range(num_mixtures):\n",
    "#     generator = dataset_generator(fg_folder, bg_folder, template_event_parameters, seed + i)\n",
    "#     for data in generator:\n",
    "#         X, y = data\n",
    "#         print(\"X =\", X.shape)\n",
    "#         print(\"y_fg =\", y[0].shape)\n",
    "#         print(\"y_bg =\", y[1].shape)\n",
    "#         break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import numpy as np\n",
    "# import librosa\n",
    "# import scaper\n",
    "# from sklearn.preprocessing import MinMaxScaler\n",
    "# from IPython.display import Audio\n",
    "# from pathlib import Path\n",
    "# import matplotlib.pyplot as plt\n",
    "# from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# template_event_parameters = {\n",
    "#     'label': ('const', 'vocals'),\n",
    "#     'source_file': ('choose', []),\n",
    "#     'source_time': ('uniform', 0, 7),\n",
    "#     'event_time': ('const', 0),\n",
    "#     'event_duration': ('const', 6.0),\n",
    "#     'snr': ('uniform', -5, 5),\n",
    "#     'pitch_shift': ('uniform', -2, 2),\n",
    "#     'time_stretch': ('uniform', 0.8, 1.2)\n",
    "# }\n",
    "\n",
    "# # create foreground folder\n",
    "# fg_folder = Path('~/.nussl/ismir2020-tutorial/foreground').expanduser()  \n",
    "# fg_folder.mkdir(parents=True, exist_ok=True)                             \n",
    "\n",
    "# # create background folder - we need to provide one even if we don't use it\n",
    "# bg_folder = Path('~/.nussl/ismir2020-tutorial/background').expanduser()\n",
    "# bg_folder.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# def spectrogram_to_audio(spectrogram):\n",
    "\n",
    "#     # Use the Griffin-Lim algorithm to reconstruct the audio waveform\n",
    "#     audio = librosa.griffinlim(spectrogram)\n",
    "    \n",
    "#     return audio\n",
    "\n",
    "# # Your provided functions\n",
    "# def generate_spectrograms(mixture_audio, stem_audio_list):\n",
    "#     mixture_spectrogram = np.abs(librosa.stft(mixture_audio.squeeze())).astype(np.float32)\n",
    "#     stem_spectrograms = [np.abs(librosa.stft(stem_audio.squeeze())).astype(np.float32) for stem_audio in stem_audio_list]\n",
    "#     return mixture_spectrogram, stem_spectrograms\n",
    "\n",
    "# def preprocess_audio(audio):\n",
    "#     scaler = MinMaxScaler()\n",
    "#     audio = audio.reshape(audio.shape[0], -1)\n",
    "#     preprocessed_audio = scaler.fit_transform(audio).reshape(audio.shape)\n",
    "#     return preprocessed_audio, scaler\n",
    "\n",
    "# def postprocess_audio(preprocessed_audio, scaler):\n",
    "#     preprocessed_audio = preprocessed_audio.reshape(preprocessed_audio.shape[0], -1)\n",
    "#     audio = scaler.inverse_transform(preprocessed_audio).reshape(preprocessed_audio.shape)\n",
    "#     return audio\n",
    "\n",
    "# def dataset_generator_tester(fg_folder, bg_folder, template_event_parameters, seed, batch_size=1):\n",
    "#     while True:\n",
    "#         X_batch = []\n",
    "#         y_batch = []\n",
    "        \n",
    "#         for _ in range(batch_size):\n",
    "#             mixture_audio, mixture_jam, annotation_list, stem_audio_list = incoherent(fg_folder, bg_folder, template_event_parameters, seed)\n",
    "#             mixture_spectrogram, stem_spectrograms = generate_spectrograms(mixture_audio, stem_audio_list)\n",
    "\n",
    "#             X, scaler = preprocess_audio(mixture_spectrogram)\n",
    "#             y = [preprocess_audio(stem_spectrogram)[0] for stem_spectrogram in stem_spectrograms]\n",
    "            \n",
    "#             X_batch.append(X)\n",
    "#             y_batch.append(y)\n",
    "        \n",
    "#         X_batch = np.stack(X_batch, axis=0)\n",
    "#         y_batch = np.stack(y_batch, axis=0)\n",
    "        \n",
    "#         yield X_batch, y_batch, mixture_audio, stem_audio_list\n",
    "\n",
    "# seed = 42\n",
    "# mse_losses = []\n",
    "# num_mixtures = np.random.randint(1, 2)\n",
    "\n",
    "# # Loop through the generator to retrieve X and y values\n",
    "# for i in range(num_mixtures):\n",
    "#     generator = dataset_generator_tester(fg_folder, bg_folder, template_event_parameters, seed + i)\n",
    "#     for data in generator:\n",
    "#         X, y, mixture_audio, stem_audio_list = data\n",
    "#         print(\"X =\", X.shape)\n",
    "#         print(\"y =\", y.shape)\n",
    "        \n",
    "#         # Play the original audio\n",
    "#         print(\"Original audio:\")\n",
    "#         display(Audio(mixture_audio.squeeze(), rate=441000))\n",
    "        \n",
    "#         # Convert audio to spectrogram\n",
    "#         mixture_spectrogram, stem_spectrograms = generate_spectrograms(mixture_audio, stem_audio_list)\n",
    "        \n",
    "#         # Preprocess, then postprocess the spectrogram\n",
    "#         preprocessed_spectrogram, scaler = preprocess_audio(mixture_spectrogram)\n",
    "#         reconstructed_spectrogram = postprocess_audio(preprocessed_spectrogram, scaler)\n",
    "        \n",
    "#         # Convert the spectrogram back to audio\n",
    "#         reconstructed_audio = spectrogram_to_audio(reconstructed_spectrogram)\n",
    "        \n",
    "#         # Play the reconstructed audio\n",
    "#         print(\"Reconstructed audio:\")\n",
    "#         display(Audio(reconstructed_audio, rate=441000))\n",
    "        \n",
    "#         # mse_loss = mean_squared_error(mixture_audio.squeeze(), reconstructed_audio)\n",
    "#         # Calculate the loss for the overlapping portion of the signals\n",
    "#         min_length = min(len(mixture_audio.squeeze()), len(reconstructed_audio))\n",
    "#         mse_loss = mean_squared_error(mixture_audio.squeeze()[:min_length], reconstructed_audio[:min_length])\n",
    "\n",
    "#         min_length = min(len(mixture_audio.squeeze()), len(reconstructed_audio))\n",
    "#         trimmed_mixture_audio = mixture_audio.squeeze()[:min_length]\n",
    "#         trimmed_reconstructed_audio = reconstructed_audio[:min_length]\n",
    "        \n",
    "#         # Compute spectrograms\n",
    "#         original_spectrogram = np.abs(librosa.stft(trimmed_mixture_audio))\n",
    "#         reconstructed_spectrogram = np.abs(librosa.stft(trimmed_reconstructed_audio))\n",
    "\n",
    "#         # Plot spectrograms\n",
    "#         fig, axes = plt.subplots(1, 2, figsize=(20, 6), sharey=True)\n",
    "\n",
    "#         img = axes[0].imshow(original_spectrogram, origin='lower', aspect='auto', cmap='viridis')\n",
    "#         axes[0].set_title('Original Spectrogram')\n",
    "#         axes[0].set_xlabel('Time (frames)')\n",
    "#         axes[0].set_ylabel('Frequency (bins)')\n",
    "\n",
    "#         img = axes[1].imshow(reconstructed_spectrogram, origin='lower', aspect='auto', cmap='viridis')\n",
    "#         axes[1].set_title('Reconstructed Spectrogram')\n",
    "#         axes[1].set_xlabel('Time (frames)')\n",
    "#         axes[1].set_ylabel('Frequency (bins)')\n",
    "\n",
    "#         fig.colorbar(img, ax=axes.ravel().tolist(), pad=0.02)\n",
    "#         plt.show()\n",
    "\n",
    "\n",
    "#         mse_loss = mean_squared_error(trimmed_mixture_audio, trimmed_reconstructed_audio)\n",
    "#         mse_losses.append(mse_loss)\n",
    "\n",
    "#         # Print the MSE loss\n",
    "#         print(f\"MSE Loss: {mse_loss:.6f}\")\n",
    "#         break\n",
    "\n",
    "\n",
    "# # Create a bar plot of the MSE losses\n",
    "# # Plot waveforms\n",
    "# plt.figure(figsize=(15, 6))\n",
    "# plt.plot(trimmed_mixture_audio, label='Original', alpha=0.7)\n",
    "# plt.plot(trimmed_reconstructed_audio, label='Reconstructed', alpha=0.7)\n",
    "# plt.legend()\n",
    "# plt.xlabel('Time (samples)')\n",
    "# plt.ylabel('Amplitude')\n",
    "# plt.title('Waveforms: Original vs. Reconstructed Audio')\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# def preprocess_audio(audio):\n",
    "#     scaler = MinMaxScaler()\n",
    "#     audio = audio.reshape(audio.shape[0], -1)\n",
    "#     preprocessed_audio = scaler.fit_transform(audio).reshape(audio.shape)\n",
    "\n",
    "#     return preprocessed_audio, scaler\n",
    "\n",
    "# def dataset_generator(fg_folder, bg_folder, template_event_parameters, seed, batch_size=1):\n",
    "#     while True:\n",
    "#         X_batch = []\n",
    "#         y_batch = []\n",
    "#         stem_names_batch = []\n",
    "#         scalers_batch = []\n",
    "\n",
    "#         for _ in range(batch_size):\n",
    "#             mixture_audio, mixture_jam, annotation_list, stem_audio_list = incoherent(fg_folder, bg_folder, template_event_parameters, seed)\n",
    "#             x = mixture_audio[:, np.newaxis]\n",
    "#             y = np.stack([stem_audio[:, np.newaxis] for stem_audio in stem_audio_list], axis=0)\n",
    "\n",
    "#             X, X_scaler = preprocess_audio(mixture_audio)\n",
    "#             y, y_scalers = zip(*[preprocess_audio(stem_audio) for stem_audio in stem_audio_list])\n",
    "\n",
    "#             X_batch.append(X)\n",
    "#             y_batch.append(y)\n",
    "#             stem_names_batch.append(annotation_list)\n",
    "#             scalers_batch.append((X_scaler, y_scalers))\n",
    "\n",
    "#         X_batch = np.stack(X_batch, axis=0)\n",
    "#         y_batch = np.stack(y_batch, axis=0)\n",
    "        \n",
    "#         yield X_batch, y_batch, stem_names_batch, scalers_batch\n",
    "\n",
    "# num_mixtures = np.random.randint(1, 2)\n",
    "\n",
    "# # Loop through the generator to retrieve X and y values\n",
    "# for i in range(num_mixtures):\n",
    "#     generator = dataset_generator(fg_folder, bg_folder, template_event_parameters, seed + i)\n",
    "#     for data in generator:\n",
    "#         X, y, stem_names, scalers = data\n",
    "#         print(\"X =\", X.shape)\n",
    "#         print(\"y =\", y.shape)\n",
    "#         print(\"Stem names =\", stem_names)\n",
    "#         break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# from sklearn.preprocessing import MinMaxScaler\n",
    "# import librosa\n",
    "# from IPython.display import Audio\n",
    "\n",
    "# def preprocess_audio(audio):\n",
    "#     scaler = MinMaxScaler()\n",
    "#     audio = audio.reshape(audio.shape[0], -1)\n",
    "#     preprocessed_audio = scaler.fit_transform(audio).reshape(audio.shape)\n",
    "\n",
    "#     return preprocessed_audio, scaler\n",
    "\n",
    "# def inverse_transform_stem(stem, scaler):\n",
    "#     stem = stem.reshape(stem.shape[0], -1)\n",
    "#     inv_transformed_stem = scaler.inverse_transform(stem).reshape(stem.shape)\n",
    "#     return inv_transformed_stem\n",
    "\n",
    "# def dataset_generator(fg_folder, bg_folder, template_event_parameters, seed, batch_size=1):\n",
    "#     while True:\n",
    "#         X_batch = []\n",
    "#         y_batch = []\n",
    "#         stem_names_batch = []\n",
    "#         scalers_batch = []\n",
    "\n",
    "#         for _ in range(batch_size):\n",
    "#             mixture_audio, mixture_jam, annotation_list, stem_audio_list = incoherent(fg_folder, bg_folder, template_event_parameters, seed)\n",
    "#             x = mixture_audio[:, np.newaxis]\n",
    "#             y = np.stack([stem_audio[:, np.newaxis] for stem_audio in stem_audio_list], axis=0)\n",
    "\n",
    "#             X, X_scaler = preprocess_audio(mixture_audio)\n",
    "#             y, y_scalers = zip(*[preprocess_audio(stem_audio) for stem_audio in stem_audio_list])\n",
    "\n",
    "#             X_batch.append(X)\n",
    "#             y_batch.append(y)\n",
    "#             stem_names_batch.append(annotation_list)\n",
    "#             scalers_batch.append((X_scaler, y_scalers))\n",
    "\n",
    "#         X_batch = np.stack(X_batch, axis=0)\n",
    "#         y_batch = np.stack(y_batch, axis=0)\n",
    "        \n",
    "#         # Inverse transform the stems and display the audio\n",
    "#         for i, stem in enumerate(y_batch[0]):\n",
    "#             stem_name = stem_names_batch[0][i][2]\n",
    "#             stem_scaler = scalers_batch[0][1][i]\n",
    "\n",
    "#             # Inverse transform the stem\n",
    "#             inv_transformed_stem = inverse_transform_stem(stem, stem_scaler)\n",
    "\n",
    "#             # Display the stem as an audio\n",
    "#             display(Audio(inv_transformed_stem[:, 0], rate=44100))\n",
    "        \n",
    "#         yield X_batch, y_batch, stem_names_batch, scalers_batch\n",
    "\n",
    "# num_mixtures = np.random.randint(1, 2)\n",
    "\n",
    "# # Loop through the generator to retrieve X and y values\n",
    "# for i in range(num_mixtures):\n",
    "#     generator = dataset_generator(fg_folder, bg_folder, template_event_parameters, seed + i)\n",
    "#     for data in generator:\n",
    "#         X, y, stem_names, scalers = data\n",
    "#         print(\"X =\", X.shape)\n",
    "#         print(\"y =\", y.shape)\n",
    "#         print(\"Stem names =\", stem_names)\n",
    "#         break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X = (1, 264600, 129, 1)\n",
      "y = (4, 264600, 129, 1)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import librosa\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "\n",
    "def preprocess_audio(audio, n_fft=256, hop_length=128):\n",
    "    # Compute the spectrogram\n",
    "    spectrogram = np.abs(librosa.stft(audio, n_fft=n_fft, hop_length=hop_length))\n",
    "\n",
    "    # Normalize the spectrogram\n",
    "    scaler = MinMaxScaler()\n",
    "    original_shape = spectrogram.shape\n",
    "    spectrogram = scaler.fit_transform(spectrogram.flatten().reshape(-1, 1)).reshape(original_shape)\n",
    "\n",
    "    return spectrogram\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def dataset_generator(fg_folder, bg_folder, template_event_parameters, seed, batch_size=1, n_fft=256, hop_length=128):\n",
    "    while True:\n",
    "        X_batch = []\n",
    "        y_batch = []\n",
    "\n",
    "        for _ in range(batch_size):\n",
    "            mixture_audio, mixture_jam, annotation_list, stem_audio_list = incoherent(fg_folder, bg_folder, template_event_parameters, seed)\n",
    "\n",
    "            X = preprocess_audio(mixture_audio, n_fft=n_fft, hop_length=hop_length)\n",
    "            y = np.array([preprocess_audio(stem_audio, n_fft=n_fft, hop_length=hop_length) for stem_audio in stem_audio_list])\n",
    "\n",
    "            X_batch.append(X[np.newaxis, :, :])\n",
    "            y_batch.append(y)\n",
    "\n",
    "        X_batch = np.concatenate(X_batch, axis=0)\n",
    "        y_batch = np.concatenate(y_batch, axis=0)\n",
    "\n",
    "        yield X_batch, y_batch\n",
    "\n",
    "num_mixtures = np.random.randint(1, 2)\n",
    "\n",
    "# Loop through the generator to retrieve X and y values\n",
    "for i in range(num_mixtures):\n",
    "    generator = dataset_generator(fg_folder, bg_folder, template_event_parameters, seed + i)\n",
    "    for data in generator:\n",
    "        X, y = data[:2]\n",
    "        # print(f\"Mixture {i + 1}:\")\n",
    "        print(\"X =\", X.shape)\n",
    "        print(\"y =\", y.shape)\n",
    "        break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import librosa\n",
    "# import tensorflow as tf\n",
    "# from tensorflow.keras.optimizers import RMSprop\n",
    "# from tensorflow.keras.layers import (Input, Conv1D, MaxPooling1D, UpSampling1D,\n",
    "#                                      concatenate, ZeroPadding1D, Reshape, BatchNormalization)\n",
    "# from tensorflow.keras.models import Model\n",
    "\n",
    "\n",
    "# def unet_model(input_shape, num_sources):\n",
    "#     inputs = Input(input_shape)\n",
    "\n",
    "#     def conv_block(inputs, filters):\n",
    "#         conv = Conv1D(filters, 3, activation='relu', padding='same')(inputs)\n",
    "#         conv = BatchNormalization()(conv)\n",
    "#         conv = Conv1D(filters, 3, activation='relu', padding='same')(conv)\n",
    "#         conv = BatchNormalization()(conv)\n",
    "#         return conv\n",
    "\n",
    "#     # Encoder\n",
    "#     conv1 = conv_block(inputs, 32)\n",
    "#     pool1 = MaxPooling1D(pool_size=2)(conv1)\n",
    "\n",
    "#     conv2 = conv_block(pool1, 64)\n",
    "#     pool2 = MaxPooling1D(pool_size=2)(conv2)\n",
    "\n",
    "#     conv3 = conv_block(pool2, 128)\n",
    "#     pool3 = MaxPooling1D(pool_size=2)(conv3)\n",
    "\n",
    "#     conv4 = conv_block(pool3, 256)\n",
    "#     pool4 = MaxPooling1D(pool_size=2)(conv4)\n",
    "\n",
    "#     # Bottleneck\n",
    "#     conv5 = conv_block(pool4, 512)\n",
    "\n",
    "#     # Decoder\n",
    "#     up6 = UpSampling1D(size=2)(conv5)\n",
    "#     up6 = ZeroPadding1D(padding=(0, 1))(up6)  # Add this line\n",
    "#     up6 = concatenate([up6, conv4], axis=-1)\n",
    "#     conv6 = conv_block(up6, 256)\n",
    "\n",
    "#     up7 = concatenate([UpSampling1D(size=2)(conv6), conv3], axis=-1)\n",
    "#     conv7 = conv_block(up7, 128)\n",
    "\n",
    "#     up8 = concatenate([UpSampling1D(size=2)(conv7), conv2], axis=-1)\n",
    "#     conv8 = conv_block(up8, 64)\n",
    "\n",
    "#     up9 = UpSampling1D(size=2)(conv8)\n",
    "#     up9 = concatenate([up9, conv1], axis=-1)\n",
    "#     conv9 = conv_block(up9, 32)\n",
    "\n",
    "#     # Output layer\n",
    "#     outputs = Conv1D(num_sources, 1, activation='linear', padding='same')(conv9)\n",
    "#     outputs = Reshape((num_sources, -1, 1))(outputs)\n",
    "\n",
    "#     return Model(inputs=[inputs], outputs=[outputs])\n",
    "\n",
    "# num_sources = 4\n",
    "# input_shape = (264600, 1)\n",
    "\n",
    "# # Create the U-Net model\n",
    "# model = unet_model(input_shape, num_sources)\n",
    "# model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import librosa\n",
    "# import tensorflow as tf\n",
    "# from tensorflow.keras.optimizers import RMSprop\n",
    "# from tensorflow.keras.layers import Input, Conv1D, MaxPooling1D, UpSampling1D, Conv1DTranspose, concatenate, ZeroPadding1D, Reshape, BatchNormalization, Dropout\n",
    "# from tensorflow.keras.models import Model\n",
    "\n",
    "# def unet_model(input_shape, num_sources):\n",
    "#     inputs = Input(input_shape)\n",
    "\n",
    "#     # Encoder\n",
    "#     conv1 = Conv1D(16, 3, activation='relu', padding='same')(inputs)\n",
    "#     conv1 = BatchNormalization()(conv1)\n",
    "#     conv1 = Dropout(0.1)(conv1)\n",
    "#     pool1 = MaxPooling1D(pool_size=2)(conv1)\n",
    "\n",
    "#     conv2 = Conv1D(32, 3, activation='relu', padding='same')(pool1)\n",
    "#     conv2 = BatchNormalization()(conv2)\n",
    "#     conv2 = Dropout(0.1)(conv2)\n",
    "#     pool2 = MaxPooling1D(pool_size=2)(conv2)\n",
    "\n",
    "#     # Bottleneck\n",
    "#     conv3 = Conv1D(64, 3, activation='relu', padding='same')(pool2)\n",
    "#     conv3 = BatchNormalization()(conv3)\n",
    "#     conv3 = Dropout(0.1)(conv3)\n",
    "\n",
    "#     # Decoder\n",
    "#     up4 = concatenate([Conv1DTranspose(32, 2, strides=2, padding='same')(conv3), conv2], axis=-1)\n",
    "#     conv4 = Conv1D(32, 3, activation='relu', padding='same')(up4)\n",
    "#     conv4 = BatchNormalization()(conv4)\n",
    "#     conv4 = Dropout(0.1)(conv4)\n",
    "\n",
    "#     up5 = Conv1DTranspose(16, 2, strides=2, padding='same')(conv4)\n",
    "#     up5 = concatenate([up5, conv1], axis=-1)\n",
    "\n",
    "#     conv5 = Conv1D(16, 3, activation='relu', padding='same')(up5)\n",
    "#     conv5 = BatchNormalization()(conv5)\n",
    "#     conv5 = Dropout(0.1)(conv5)\n",
    "\n",
    "#     # Output layer\n",
    "#     outputs = Conv1D(num_sources, 1, activation='linear', padding='same')(conv5)\n",
    "#     outputs = Reshape((num_sources, -1, 1))(outputs)\n",
    "\n",
    "#     return Model(inputs=[inputs], outputs=[outputs])\n",
    "\n",
    "# input_shape = (264600, 1)\n",
    "\n",
    "# # Create the U-Net model\n",
    "# model = unet_model(input_shape, num_sources)\n",
    "# model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 264600, 129  0           []                               \n",
      "                                , 1)]                                                             \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)                (None, 264600, 129,  80          ['input_1[0][0]']                \n",
      "                                 8)                                                               \n",
      "                                                                                                  \n",
      " max_pooling2d (MaxPooling2D)   (None, 132300, 64,   0           ['conv2d[0][0]']                 \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)              (None, 132300, 64,   1168        ['max_pooling2d[0][0]']          \n",
      "                                16)                                                               \n",
      "                                                                                                  \n",
      " max_pooling2d_1 (MaxPooling2D)  (None, 66150, 32, 1  0          ['conv2d_1[0][0]']               \n",
      "                                6)                                                                \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)              (None, 66150, 32, 3  4640        ['max_pooling2d_1[0][0]']        \n",
      "                                2)                                                                \n",
      "                                                                                                  \n",
      " conv2d_transpose (Conv2DTransp  (None, 132300, 64,   2064       ['conv2d_2[0][0]']               \n",
      " ose)                           16)                                                               \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 132300, 64,   0           ['conv2d_transpose[0][0]',       \n",
      "                                32)                               'conv2d_1[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)              (None, 132300, 64,   4624        ['concatenate[0][0]']            \n",
      "                                16)                                                               \n",
      "                                                                                                  \n",
      " conv2d_transpose_1 (Conv2DTran  (None, 264600, 128,  520        ['conv2d_3[0][0]']               \n",
      " spose)                          8)                                                               \n",
      "                                                                                                  \n",
      " cropping2d (Cropping2D)        (None, 264600, 128,  0           ['conv2d[0][0]']                 \n",
      "                                 8)                                                               \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 264600, 128,  0           ['conv2d_transpose_1[0][0]',     \n",
      "                                 16)                              'cropping2d[0][0]']             \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)              (None, 264600, 128,  1160        ['concatenate_1[0][0]']          \n",
      "                                 8)                                                               \n",
      "                                                                                                  \n",
      " conv2d_5 (Conv2D)              (None, 264600, 128,  36          ['conv2d_4[0][0]']               \n",
      "                                 4)                                                               \n",
      "                                                                                                  \n",
      " reshape (Reshape)              (None, 4, 33868800,  0           ['conv2d_5[0][0]']               \n",
      "                                 1)                                                               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 14,292\n",
      "Trainable params: 14,292\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import librosa\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Conv2DTranspose, concatenate, ZeroPadding1D, Reshape, BatchNormalization, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Cropping2D\n",
    "\n",
    "def unet_model(input_shape, num_sources):\n",
    "    inputs = Input(input_shape)\n",
    "\n",
    "    # Encoder\n",
    "    conv1 = Conv2D(8, (3, 3), activation='relu', padding='same')(inputs)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "\n",
    "    conv2 = Conv2D(16, (3, 3), activation='relu', padding='same')(pool1)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "\n",
    "    # Bottleneck\n",
    "    conv3 = Conv2D(32, (3, 3), activation='relu', padding='same')(pool2)\n",
    "\n",
    "    # Decoder\n",
    "    up4 = concatenate([Conv2DTranspose(16, (2, 2), strides=(2, 2), padding='same')(conv3), conv2], axis=-1)\n",
    "    conv4 = Conv2D(16, (3, 3), activation='relu', padding='same')(up4)\n",
    "\n",
    "    up5 = Conv2DTranspose(8, (2, 2), strides=(2, 2), padding='same')(conv4)\n",
    "    # Crop the conv1 layer to match the dimensions\n",
    "    cropped_conv1 = Cropping2D(cropping=((0, 0), (1, 0)))(conv1)\n",
    "    up5 = concatenate([up5, cropped_conv1], axis=-1)\n",
    "\n",
    "    conv5 = Conv2D(8, (3, 3), activation='relu', padding='same')(up5)\n",
    "\n",
    "    # Output layer\n",
    "    outputs = Conv2D(num_sources, (1, 1), activation='linear', padding='same')(conv5)\n",
    "\n",
    "    # Reshape the output to match the target shape\n",
    "    outputs = Reshape((num_sources, -1, 1))(outputs)\n",
    "\n",
    "    return Model(inputs=[inputs], outputs=[outputs])\n",
    "\n",
    "time_steps, frequency_bins = X.shape[1], X.shape[2]\n",
    "input_shape = (time_steps, frequency_bins, 1)\n",
    "num_sources = 4\n",
    "\n",
    "# Create the U-Net model\n",
    "model = unet_model(input_shape, num_sources)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras.backend as K\n",
    "import tensorflow as tf\n",
    "\n",
    "def accuracy_percentage(y_true, y_pred):\n",
    "    mae = K.mean(K.abs(y_true - y_pred), axis=-1)\n",
    "    accuracy = 100 * (1 - mae)\n",
    "    return K.mean(accuracy)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Compile the model with the custom metric\n",
    "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate=0.01,\n",
    "    decay_steps=10000,\n",
    "    decay_rate=0.9)\n",
    "\n",
    "optimizer = RMSprop(learning_rate=lr_schedule)\n",
    "\n",
    "model.compile(optimizer=optimizer, loss=\"mae\", metrics=[accuracy_percentage])\n",
    "\n",
    "# Define the data generators\n",
    "train_generator = dataset_generator(fg_folder, bg_folder, template_event_parameters, seed, batch_size=4)\n",
    "validation_generator = dataset_generator(fg_folder, bg_folder, template_event_parameters, seed + 1, batch_size=4)\n",
    "\n",
    "# Define the number of training and validation steps per epoch\n",
    "num_train_steps = 2\n",
    "num_validation_steps = 1\n",
    "\n",
    "# Define early stopping callback\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(train_generator, steps_per_epoch=num_train_steps,\n",
    "                    validation_data=validation_generator, validation_steps=num_validation_steps,\n",
    "                    epochs=30, callbacks=[early_stopping])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "folder_path = 'my_first_model'\n",
    "\n",
    "def save_model(model, folder_path):\n",
    "    # Create the folder if it doesn't already exist\n",
    "    if not os.path.exists(folder_path):\n",
    "        os.makedirs(folder_path)\n",
    "    \n",
    "    # Save the model to the folder\n",
    "    model.save(os.path.join(folder_path, 'my_main_working_new_Unet_model.h5'))\n",
    "\n",
    "\n",
    "save_model(model, folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_training_history(history):\n",
    "    # Plot training & validation accuracy values\n",
    "    plt.figure()\n",
    "    plt.plot(history.history[\"accuracy_percentage\"])\n",
    "    # plt.plot(history.history['loss'])\n",
    "    plt.title('Model accuracy')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "    plt.show()\n",
    "\n",
    "    # Plot training & validation loss values\n",
    "    plt.figure()\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('Model loss')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "    plt.show()\n",
    "plot_training_history(history)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_audio(spectrogram):\n",
    "    print(spectrogram.shape) # Add this line\n",
    "    # Apply log amplitude compression\n",
    "    log_spectrogram = np.log10(1 + 10000 * np.abs(spectrogram) ** 2)\n",
    "    print(log_spectrogram.shape) # Add this line\n",
    "    # Scale the values between 0 and 1\n",
    "    scaler = MinMaxScaler()\n",
    "    scaled_spectrogram = scaler.fit_transform(log_spectrogram)\n",
    "    print(scaled_spectrogram.shape) # Add this line\n",
    "    # Add a channel dimension\n",
    "    X = np.expand_dims(scaled_spectrogram, axis=-1)\n",
    "    return X, scaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_generator_wrapper(fg_folder, bg_folder, template_event_parameters, seed, batch_size):\n",
    "    generator = data_generator(fg_folder, bg_folder, template_event_parameters, seed=seed, batch_size=batch_size)\n",
    "    while True:\n",
    "        X_batch = []\n",
    "        y_batch = []\n",
    "        mixture_audio_list = []\n",
    "        stem_audio_list_list = []\n",
    "        scaler_list = []\n",
    "        for i in range(batch_size):\n",
    "            X, y, mixture_audio, stem_audio_list = next(generator)\n",
    "            print(f\"X.shape: {X.shape}, y.shape: {y.shape}, mixture_audio.shape: {mixture_audio.shape}, stem_audio_list: {len(stem_audio_list)}\") # Add this line\n",
    "            mixture_spectrogram, stem_spectrograms = generate_spectrograms(mixture_audio, stem_audio_list)\n",
    "            X, scaler = preprocess_audio(mixture_spectrogram)\n",
    "            y = [preprocess_audio(stem_spectrogram)[0] for stem_spectrogram in stem_spectrograms]\n",
    "            X_batch.append(X)\n",
    "            y_batch.append(y)\n",
    "            mixture_audio_list.append(mixture_audio)\n",
    "            stem_audio_list_list.append(stem_audio_list)\n",
    "            scaler_list.append(scaler)\n",
    "        yield np.array(X_batch), np.array(y_batch), mixture_audio_list, stem_audio_list_list, scaler_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_predictions(model, data_generator, num_samples=1):\n",
    "    test_generator = data_generator(fg_folder, bg_folder, template_event_parameters, seed=100, batch_size=1)\n",
    "    for i in range(num_samples):\n",
    "        # Get the next sample from the data generator\n",
    "        X_test, y_test, mixture_audio_list, stem_audio_list_list, scaler_list = next(test_generator)\n",
    "        \n",
    "        # Predict the separated sources\n",
    "        y_pred = model.predict(X_test)\n",
    "        \n",
    "        # Postprocess the audio and convert it to audio signals\n",
    "        ground_truth_sources = []\n",
    "        pred_sources = []\n",
    "        ground_truth_spectrograms = []\n",
    "        pred_spectrograms = []\n",
    "        for i in range(len(y_pred)):\n",
    "            pred_spectrogram = postprocess_audio_2(y_pred[i], scaler_list[i])\n",
    "            ground_truth_spectrogram = postprocess_audio_2(y_test[i], scaler_list[i])\n",
    "            \n",
    "            pred_sources.append(spectrogram_to_audio(pred_spectrogram))\n",
    "            ground_truth_sources.append(spectrogram_to_audio(ground_truth_spectrogram))\n",
    "            pred_spectrograms.append(pred_spectrogram)\n",
    "            ground_truth_spectrograms.append(ground_truth_spectrogram)\n",
    "\n",
    "        # Plot the original audio, ground truth, and predicted sources\n",
    "        plt.figure(figsize=(20, 10))\n",
    "        plt.subplot(3, 1, 1)\n",
    "        plt.plot(mixture_audio_list[0])\n",
    "        plt.title(\"Original Audio\")\n",
    "        plt.subplot(3, 1, 2)\n",
    "        plt.plot(stem_audio_list_list[0][0])\n",
    "        plt.title(\"Ground Truth\")\n",
    "        plt.subplot(3, 1, 3)\n",
    "        plt.plot(pred_sources[0])\n",
    "        plt.title(\"Predicted Source\")\n",
    "        plt.show()\n",
    "\n",
    "        # Plot the original and predicted spectrograms\n",
    "        plt.figure(figsize=(20, 10))\n",
    "        plt.subplot(2, 1, 1)\n",
    "        plt.imshow(np.log10(ground_truth_spectrograms[0]), cmap='viridis', aspect='auto')\n",
    "        plt.title(\"Original Spectrogram\")\n",
    "        plt.subplot(2, 1, 2)\n",
    "        plt.imshow(np.log10(pred_spectrograms[0]), cmap='viridis', aspect='auto')\n",
    "        plt.title(\"Predicted Spectrogram\")\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data_generator' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[311], line 5\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodels\u001b[39;00m \u001b[39mimport\u001b[39;00m load_model\n\u001b[0;32m      3\u001b[0m model \u001b[39m=\u001b[39m load_model(\u001b[39m'\u001b[39m\u001b[39mmy_first_model\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mmy_basic_Unet_model.h5\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m----> 5\u001b[0m display_predictions(model, test_generator_wrapper, num_samples\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\n",
      "Cell \u001b[1;32mIn[310], line 5\u001b[0m, in \u001b[0;36mdisplay_predictions\u001b[1;34m(model, data_generator, num_samples)\u001b[0m\n\u001b[0;32m      2\u001b[0m test_generator \u001b[39m=\u001b[39m data_generator(fg_folder, bg_folder, template_event_parameters, seed\u001b[39m=\u001b[39m\u001b[39m100\u001b[39m, batch_size\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m      3\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(num_samples):\n\u001b[0;32m      4\u001b[0m     \u001b[39m# Get the next sample from the data generator\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m     X_test, y_test, mixture_audio_list, stem_audio_list_list, scaler_list \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39;49m(test_generator)\n\u001b[0;32m      7\u001b[0m     \u001b[39m# Predict the separated sources\u001b[39;00m\n\u001b[0;32m      8\u001b[0m     y_pred \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mpredict(X_test)\n",
      "Cell \u001b[1;32mIn[309], line 2\u001b[0m, in \u001b[0;36mtest_generator_wrapper\u001b[1;34m(fg_folder, bg_folder, template_event_parameters, seed, batch_size)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtest_generator_wrapper\u001b[39m(fg_folder, bg_folder, template_event_parameters, seed, batch_size):\n\u001b[1;32m----> 2\u001b[0m     generator \u001b[39m=\u001b[39m data_generator(fg_folder, bg_folder, template_event_parameters, seed\u001b[39m=\u001b[39mseed, batch_size\u001b[39m=\u001b[39mbatch_size)\n\u001b[0;32m      3\u001b[0m     \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m      4\u001b[0m         X_batch \u001b[39m=\u001b[39m []\n",
      "\u001b[1;31mNameError\u001b[0m: name 'data_generator' is not defined"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "model = load_model('my_first_model\\my_basic_Unet_model.h5')\n",
    "\n",
    "display_predictions(model, test_generator_wrapper, num_samples=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000029B4AFB8310> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000029B4AFB8310> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 136s 136s/step\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "non-broadcastable output operand with shape (4,1) doesn't match the broadcast shape (4,517)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[283], line 58\u001b[0m\n\u001b[0;32m     55\u001b[0m ground_truth_sources \u001b[39m=\u001b[39m []\n\u001b[0;32m     57\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(y_pred)):\n\u001b[1;32m---> 58\u001b[0m     pred_spectrogram \u001b[39m=\u001b[39m postprocess_audio_2(y_pred[i], scaler_list[\u001b[39m0\u001b[39;49m])\n\u001b[0;32m     59\u001b[0m     ground_truth_spectrogram \u001b[39m=\u001b[39m postprocess_audio_2(y_test[i], scaler_list[\u001b[39m0\u001b[39m])\n\u001b[0;32m     61\u001b[0m     pred_sources\u001b[39m.\u001b[39mappend(spectrogram_to_audio(pred_spectrogram))\n",
      "Cell \u001b[1;32mIn[283], line 12\u001b[0m, in \u001b[0;36mpostprocess_audio_2\u001b[1;34m(preprocessed_audio, scaler)\u001b[0m\n\u001b[0;32m      9\u001b[0m audio \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mzeros_like(preprocessed_audio)\n\u001b[0;32m     11\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(preprocessed_audio\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m]):\n\u001b[1;32m---> 12\u001b[0m     audio[:, i] \u001b[39m=\u001b[39m scaler\u001b[39m.\u001b[39;49minverse_transform(preprocessed_audio[:, i]\u001b[39m.\u001b[39;49mreshape(\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m, \u001b[39m1\u001b[39;49m))\u001b[39m.\u001b[39mflatten()\n\u001b[0;32m     14\u001b[0m audio \u001b[39m=\u001b[39m audio\u001b[39m.\u001b[39mreshape(preprocessed_audio\u001b[39m.\u001b[39mshape)\n\u001b[0;32m     15\u001b[0m \u001b[39mreturn\u001b[39;00m audio\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\preprocessing\\_data.py:541\u001b[0m, in \u001b[0;36mMinMaxScaler.inverse_transform\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    535\u001b[0m check_is_fitted(\u001b[39mself\u001b[39m)\n\u001b[0;32m    537\u001b[0m X \u001b[39m=\u001b[39m check_array(\n\u001b[0;32m    538\u001b[0m     X, copy\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcopy, dtype\u001b[39m=\u001b[39mFLOAT_DTYPES, force_all_finite\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mallow-nan\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    539\u001b[0m )\n\u001b[1;32m--> 541\u001b[0m X \u001b[39m-\u001b[39m\u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmin_\n\u001b[0;32m    542\u001b[0m X \u001b[39m/\u001b[39m\u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mscale_\n\u001b[0;32m    543\u001b[0m \u001b[39mreturn\u001b[39;00m X\n",
      "\u001b[1;31mValueError\u001b[0m: non-broadcastable output operand with shape (4,1) doesn't match the broadcast shape (4,517)"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import librosa\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Audio\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "def postprocess_audio_2(preprocessed_audio, scaler):\n",
    "    preprocessed_audio = preprocessed_audio.reshape(preprocessed_audio.shape[0], -1)\n",
    "    audio = np.zeros_like(preprocessed_audio)\n",
    "    \n",
    "    for i in range(preprocessed_audio.shape[1]):\n",
    "        audio[:, i] = scaler.inverse_transform(preprocessed_audio[:, i].reshape(-1, 1)).flatten()\n",
    "    \n",
    "    audio = audio.reshape(preprocessed_audio.shape)\n",
    "    return audio\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Load the model (if not loaded already)\n",
    "model = load_model('my_first_model\\my_basic_Unet_model.h5')\n",
    "\n",
    "def test_generator_wrapper(fg_folder, bg_folder, template_event_parameters, seed, batch_size=1):\n",
    "    gen = dataset_generator(fg_folder, bg_folder, template_event_parameters, seed, batch_size=batch_size)\n",
    "    while True:\n",
    "        X_batch, y_batch = next(gen)\n",
    "        mixture_audio_list = []\n",
    "        stem_audio_list_list = []\n",
    "        scaler_list = []\n",
    "        \n",
    "        for i in range(batch_size):\n",
    "            mixture_audio, mixture_jam, annotation_list, stem_audio_list = incoherent(fg_folder, bg_folder, template_event_parameters, seed + i)\n",
    "            mixture_spectrogram, stem_spectrograms = generate_spectrograms(mixture_audio, stem_audio_list)\n",
    "            \n",
    "            y = [preprocess_audio(stem_spectrogram)[:2][0] for stem_spectrogram in stem_spectrograms]\n",
    "            \n",
    "            mixture_audio_list.append(mixture_audio)\n",
    "            stem_audio_list_list.append(stem_audio_list)\n",
    "            scaler_list.append(scaler)\n",
    "        \n",
    "        X_batch = np.stack(X_batch, axis=0)\n",
    "        y_batch = np.stack(y_batch, axis=0)\n",
    "        \n",
    "        yield X_batch, y_batch, mixture_audio_list, stem_audio_list_list, scaler_list\n",
    "\n",
    "# Get the test data\n",
    "test_generator = test_generator_wrapper(fg_folder, bg_folder, template_event_parameters, seed=100, batch_size=1)\n",
    "X_test, y_test, mixture_audio_list, stem_audio_list_list, scaler_list = next(test_generator)\n",
    "\n",
    "# Predict the separated sources\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Process the prediction and ground truth\n",
    "pred_sources = []\n",
    "ground_truth_sources = []\n",
    "\n",
    "for i in range(len(y_pred)):\n",
    "    pred_spectrogram = postprocess_audio_2(y_pred[i], scaler_list[0])\n",
    "    ground_truth_spectrogram = postprocess_audio_2(y_test[i], scaler_list[0])\n",
    "    \n",
    "    pred_sources.append(spectrogram_to_audio(pred_spectrogram))\n",
    "    ground_truth_sources.append(spectrogram_to_audio(ground_truth_spectrogram))\n",
    "\n",
    "\n",
    "# Visualize the spectrograms\n",
    "for i in range(len(pred_sources)):\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(20, 6), sharey=True)\n",
    "    \n",
    "    original_spectrogram = np.abs(librosa.stft(ground_truth_sources[i]))\n",
    "    reconstructed_spectrogram = np.abs(librosa.stft(pred_sources[i]))\n",
    "    \n",
    "    axes[0].imshow(original_spectrogram, origin='lower', aspect='auto', cmap='viridis')\n",
    "    axes[0].set_title(f'Original Source {i + 1} Spectrogram')\n",
    "    axes[0].set_xlabel('Time (frames)')\n",
    "    axes[0].set_ylabel('Frequency (bins)')\n",
    "\n",
    "    axes[1].imshow(reconstructed_spectrogram, origin='lower', aspect='auto', cmap='viridis')\n",
    "    axes[1].set_title(f'Reconstructed Source {i + 1} Spectrogram')\n",
    "    axes[1].set_xlabel('Time (frames)')\n",
    "    axes[1].set_ylabel('Frequency (bins)')\n",
    "    \n",
    "    fig.colorbar(img, ax=axes.ravel().tolist(), pad=0.02)\n",
    "    plt.show()\n",
    "\n",
    "# Play the original mixture\n",
    "print(\"Original Mixture Audio:\")\n",
    "display(Audio(mixture_audio.squeeze(), rate=44100))\n",
    "\n",
    "# Play the ground truth sources\n",
    "for i, source_audio in enumerate(ground_truth_sources):\n",
    "    print(f\"Ground Truth Source {i + 1}:\")\n",
    "    display(Audio(source_audio, rate=44100))\n",
    "\n",
    "# Play the predicted sources\n",
    "for i, source_audio in enumerate(pred_sources):\n",
    "    print(f\"Predicted Source {i + 1}:\")\n",
    "    display(Audio(source_audio, rate=44100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(history.history['loss'], label='Training loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "model.save('unet_model.h5')\n",
    "\n",
    "# Alternatively, save only the weights\n",
    "model.save_weights('unet_weights.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[41], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39moptimizers\u001b[39;00m \u001b[39mimport\u001b[39;00m Adam\n\u001b[0;32m      3\u001b[0m \u001b[39m# Assuming you already have the Unet model defined as 'model'\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m model\u001b[39m.\u001b[39mcompile(optimizer\u001b[39m=\u001b[39mAdam(lr\u001b[39m=\u001b[39m\u001b[39m1e-4\u001b[39m), loss\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mmean_squared_error\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m      6\u001b[0m \u001b[39m# Train the model\u001b[39;00m\n\u001b[0;32m      7\u001b[0m history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mfit(\n\u001b[0;32m      8\u001b[0m     train_generator,\n\u001b[0;32m      9\u001b[0m     validation_data\u001b[39m=\u001b[39mval_generator,\n\u001b[0;32m     10\u001b[0m     epochs\u001b[39m=\u001b[39m\u001b[39m100\u001b[39m,\n\u001b[0;32m     11\u001b[0m     verbose\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m\n\u001b[0;32m     12\u001b[0m )\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Assuming you already have the Unet model defined as 'model'\n",
    "model.compile(optimizer=Adam(lr=1e-4), loss='mean_squared_error')\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    validation_data=val_generator,\n",
    "    epochs=100,\n",
    "    verbose=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Train the model\n",
    "batch_size = 4\n",
    "epochs = 10\n",
    "steps_per_epoch = len(dataset) // batch_size\n",
    "\n",
    "model.fit(\n",
    "    dataset_generator(dataset),\n",
    "    steps_per_epoch=steps_per_epoch,\n",
    "    epochs=epochs,\n",
    "    batch_size=batch_size,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, dataloader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for batch in dataloader:\n",
    "        mix_magnitude = batch[0].to(device)\n",
    "        mix_magnitude = torch.squeeze(mix_magnitude)  # Add this line before passing the input to the model\n",
    "        source_magnitudes = batch[1].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(mix_magnitude)\n",
    "        loss = criterion(outputs, source_magnitudes)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * mix_magnitude.size(0)\n",
    "    return running_loss / len(dataloader.dataset)\n",
    "\n",
    "\n",
    "\n",
    "def validate(model, dataloader, criterion, device):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            mix_magnitude = batch[0].unsqueeze(1).to(device)\n",
    "            source_magnitudes = batch[1].to(device)\n",
    "\n",
    "            outputs = model(mix_magnitude)\n",
    "            loss = criterion(outputs, source_magnitudes)\n",
    "            running_loss += loss.item()\n",
    "\n",
    "    return running_loss / len(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Given groups=1, weight of size [512, 1, 5], expected input[1, 431, 1025] to have 1 channels, but got 431 channels instead",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[137], line 42\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(num_epochs):\n\u001b[0;32m     40\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mEpoch \u001b[39m\u001b[39m{\u001b[39;00mepoch\u001b[39m \u001b[39m\u001b[39m+\u001b[39m\u001b[39m \u001b[39m\u001b[39m1\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m{\u001b[39;00mnum_epochs\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m---> 42\u001b[0m     train_loss \u001b[39m=\u001b[39m train(model, incoherent_loader, criterion, optimizer, device)\n\u001b[0;32m     43\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mIncoherent Train Loss: \u001b[39m\u001b[39m{\u001b[39;00mtrain_loss\u001b[39m:\u001b[39;00m\u001b[39m.4f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     45\u001b[0m     train_loss \u001b[39m=\u001b[39m train(model, coherent_loader, criterion, optimizer, device)\n",
      "Cell \u001b[1;32mIn[134], line 10\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(model, dataloader, criterion, optimizer, device)\u001b[0m\n\u001b[0;32m      7\u001b[0m source_magnitudes \u001b[39m=\u001b[39m batch[\u001b[39m1\u001b[39m]\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m      9\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[1;32m---> 10\u001b[0m outputs \u001b[39m=\u001b[39m model(mix_magnitude)\n\u001b[0;32m     11\u001b[0m loss \u001b[39m=\u001b[39m criterion(outputs, source_magnitudes)\n\u001b[0;32m     12\u001b[0m loss\u001b[39m.\u001b[39mbackward()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "Cell \u001b[1;32mIn[135], line 15\u001b[0m, in \u001b[0;36mAudioSeparator.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[1;32m---> 15\u001b[0m     x \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mrelu(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconv1(x))\n\u001b[0;32m     16\u001b[0m     x \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mrelu(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconv2(x))\n\u001b[0;32m     17\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconv3(x)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\nn\\modules\\conv.py:313\u001b[0m, in \u001b[0;36mConv1d.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    312\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m--> 313\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_conv_forward(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\nn\\modules\\conv.py:309\u001b[0m, in \u001b[0;36mConv1d._conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    305\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mzeros\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m    306\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39mconv1d(F\u001b[39m.\u001b[39mpad(\u001b[39minput\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode),\n\u001b[0;32m    307\u001b[0m                     weight, bias, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstride,\n\u001b[0;32m    308\u001b[0m                     _single(\u001b[39m0\u001b[39m), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdilation, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgroups)\n\u001b[1;32m--> 309\u001b[0m \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mconv1d(\u001b[39minput\u001b[39;49m, weight, bias, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstride,\n\u001b[0;32m    310\u001b[0m                 \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpadding, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdilation, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgroups)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Given groups=1, weight of size [512, 1, 5], expected input[1, 431, 1025] to have 1 channels, but got 431 channels instead"
     ]
    }
   ],
   "source": [
    "number_of_mixtures = 2\n",
    "variations_per_mixture = 5\n",
    "\n",
    "# Replace 'AudioDataset' with 'MixtureDataset' when creating instances of the class\n",
    "incoherent_dataset = MixtureDataset(\n",
    "    fg_folder=fg_folder,\n",
    "    bg_folder=bg_folder,\n",
    "    template_event_parameters=template_event_parameters,\n",
    "    seed=seed,\n",
    "    number_of_mixtures=number_of_mixtures,\n",
    "    variations_per_mixture=variations_per_mixture,\n",
    "    mix_func=incoherent\n",
    ")\n",
    "\n",
    "coherent_dataset = MixtureDataset(\n",
    "    fg_folder=fg_folder,\n",
    "    bg_folder=bg_folder,\n",
    "    template_event_parameters=template_event_parameters,\n",
    "    seed=seed,\n",
    "    number_of_mixtures=number_of_mixtures,\n",
    "    variations_per_mixture=variations_per_mixture,\n",
    "    mix_func=coherent\n",
    ")\n",
    "\n",
    "\n",
    "batch_size = 1\n",
    "\n",
    "incoherent_loader = DataLoader(incoherent_dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "coherent_loader = DataLoader(coherent_dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = AudioSeparator().to(device)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "num_epochs = 5\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs}\")\n",
    "\n",
    "    train_loss = train(model, incoherent_loader, criterion, optimizer, device)\n",
    "    print(f\"Incoherent Train Loss: {train_loss:.4f}\")\n",
    "\n",
    "    train_loss = train(model, coherent_loader, criterion, optimizer, device)\n",
    "    print(f\"Coherent Train Loss: {train_loss:.4f}\")\n",
    "\n",
    "    val_loss = validate(model, incoherent_loader, criterion, device)\n",
    "    print(f\"Incoherent Val Loss: {val_loss:.4f}\")\n",
    "\n",
    "    val_loss = validate(model, coherent_loader, criterion, device)\n",
    "    print(f\"Coherent Val Loss: {val_loss:.4f}\")\n",
    "\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'audio_separator.pth')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f6d9ab33b054615dfb2796b001fd3c5b3bf21589efdaf15413d585f24f997c14"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
